{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73038b3b-9c64-43b3-9a6a-cb0e5b3fc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "86fbf0ef-8ae4-47e1-b912-0daec7374333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "db = lancedb.connect(\"./lancedb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "8de9c329-687b-456e-92ae-01d4b24ef31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "model_name = \"plaguss/bge-base-argilla-sdk-matryoshka\"\n",
    "device = \"mps\"\n",
    "\n",
    "model = get_registry().get(\"sentence-transformers\").create(name=model_name, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb07266-1444-486c-ad79-e21f23b32a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agus/github_repos/argilla-io/distilabel-workbench/projects/argilla-sdk-bot/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Any\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import lancedb\n",
    "from huggingface_hub.file_download import hf_hub_download\n",
    "from huggingface_hub import InferenceClient\n",
    "from transformers import AutoTokenizer\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def untar_file(source: Path) -> Path:\n",
    "    \"\"\"Untar and decompress files which have passed by `make_tarfile`.\n",
    "\n",
    "    Args:\n",
    "        source (Path): Path pointing to a .tag.gz file.\n",
    "\n",
    "    Returns:\n",
    "        filename (Path): The filename of the file decompressed.\n",
    "    \"\"\"\n",
    "    new_filename = source.parent / source.stem.replace(\".tar\", \"\")\n",
    "    with tarfile.open(source, \"r:gz\") as f:\n",
    "        f.extractall(source.parent)\n",
    "    return new_filename\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Settings:\n",
    "    LANCEDB: str = \"lancedb\"\n",
    "    LANCEDB_FILE_TAR: str = \"lancedb.tar.gz\"\n",
    "    TOKEN: str = os.getenv(\"HF_API_TOKEN\")\n",
    "    LOCAL_DIR: Path = Path.home() / \".cache/argilla_sdk_docs_db\"\n",
    "    REPO_ID: str = \"plaguss/argilla_sdk_docs_queries\"\n",
    "    TABLE_NAME: str = \"docs\"\n",
    "    MODEL_NAME: str = \"plaguss/bge-base-argilla-sdk-matryoshka\"\n",
    "    DEVICE: str = \"mps\"\n",
    "\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e74276-4135-4ad7-9f6f-286a7ff95ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Database:\n",
    "    def __init__(self, settings: Settings):\n",
    "        self.settings = settings\n",
    "        self.table = self.get_table_from_db()\n",
    "\n",
    "    def get_table_from_db(self) -> lancedb.table.LanceTable:\n",
    "        lancedb_db_path = self.settings.LOCAL_DIR / self.settings.LANCEDB\n",
    "        if not lancedb_db_path.exists():\n",
    "            lancedb_download = Path(\n",
    "                hf_hub_download(\n",
    "                    self.settings.REPO_ID,\n",
    "                    self.settings.LANCEDB_FILE_TAR,\n",
    "                    repo_type=\"dataset\",\n",
    "                    token=self.settings.TOKEN,\n",
    "                    local_dir=self.settings.LOCAL_DIR\n",
    "                )\n",
    "            )\n",
    "\n",
    "            lancedb_db_path = untar_file(lancedb_download)\n",
    "\n",
    "        db = lancedb.connect(str(lancedb_db_path))\n",
    "        table_name = \"docs\"\n",
    "        table = db.open_table(table_name)\n",
    "        return table\n",
    "\n",
    "    def retrieve_doc_chunks(self, query: str, limit: int = 12, hard_limit: int = 4) -> str:\n",
    "        retrieved = (\n",
    "            self.table\n",
    "                .search(query)\n",
    "                .metric(\"cosine\")\n",
    "                .limit(limit)\n",
    "                .select([\"text\"])  # Just grab the chunk to use for context\n",
    "                .to_list()\n",
    "        )\n",
    "        # We have repeated questions (up to 4) for a given chunk, so we may get repeated chunks.\n",
    "        # Request more than necessary and filter them afterwards\n",
    "        responses = []\n",
    "        unique_responses = set()\n",
    "\n",
    "        for item in retrieved:\n",
    "            chunk = item[\"text\"]\n",
    "            if chunk not in unique_responses:\n",
    "                unique_responses.add(chunk)\n",
    "                responses.append(chunk)\n",
    "\n",
    "        context = \"\"\n",
    "        for i, item in enumerate(responses[:hard_limit]):\n",
    "            if i > 0:\n",
    "                context += \"\\n\\n\"\n",
    "            context += f\"- {item}\"\n",
    "        return context\n",
    "\n",
    "\n",
    "database = Database(settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3287476e-9f47-46bd-9e50-5ceec5a67223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agus/github_repos/argilla-io/distilabel-workbench/projects/argilla-sdk-bot/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = get_registry().get(\"sentence-transformers\").create(name=settings.MODEL_NAME, device=settings.DEVICE)\n",
    "\n",
    "class Docs(LanceModel):\n",
    "    query: str = model.SourceField()\n",
    "    text: str = model.SourceField()\n",
    "    vector: Vector(model.ndims()) = model.VectorField()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8586e56b-1974-4b64-af40-fe966a4f1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How can I get the current user?\"\n",
    "embedded_query = model.generate_embeddings([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c998dc47-ed13-45c6-9205-b81cb036b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved = (\n",
    "    database.table\n",
    "        #.search(query)\n",
    "        .search(embedded_query[0])\n",
    "        .metric(\"cosine\")\n",
    "        .limit(3)\n",
    "        .select([\"text\"])  # Just grab the chunk to use for context\n",
    "        .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be2f1a6c-db6a-4212-80c3-80ebe41facff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'python\\nuser = client.users(\"my_username\")\\n\\nThe current user of the rg.Argilla client can be accessed using the me attribute:\\n\\npython\\nclient.me\\n\\nClass Reference\\n\\nrg.User\\n\\n::: argilla_sdk.users.User\\n    options:\\n        heading_level: 3',\n",
       "  '_distance': 0.1881886124610901},\n",
       " {'text': 'python\\nuser = client.users(\"my_username\")\\n\\nThe current user of the rg.Argilla client can be accessed using the me attribute:\\n\\npython\\nclient.me\\n\\nClass Reference\\n\\nrg.User\\n\\n::: argilla_sdk.users.User\\n    options:\\n        heading_level: 3',\n",
       "  '_distance': 0.20238929986953735},\n",
       " {'text': 'Retrieve a user\\n\\nYou can retrieve an existing user from Argilla by accessing the users attribute on the Argilla class and passing the username as an argument.\\n\\n```python\\nimport argilla_sdk as rg\\n\\nclient = rg.Argilla(api_url=\"\", api_key=\"\")\\n\\nretrieved_user = client.users(\"my_username\")\\n```',\n",
       "  '_distance': 0.20401990413665771}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9148e547-adb6-4beb-a920-3d7c59543643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanceTable(connection=LanceDBConnection(/Users/agus/.cache/argilla_sdk_docs_db/lancedb), name=\"docs\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "272bf93b-522f-4ce7-a641-6fe2178baa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add extra info, like the doc it pertains to\n",
    "\n",
    "class Docs(LanceModel):\n",
    "    query: str = model.SourceField()\n",
    "    text: str = model.SourceField()\n",
    "    vector: Vector(model.ndims()) = model.VectorField()\n",
    "\n",
    "table_name = \"docs\"\n",
    "table = db.create_table(table_name, schema=Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "29af22a7-2b15-4714-8bc6-d78b880ed785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "78fe97bf-44f5-42f8-85f9-239d1d093591",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"plaguss/argilla_sdk_docs_queries\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "30e660b1-fb2c-483c-a97c-5adec3b0c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "9393884c-f08b-469f-afdc-73ad1632f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.77it/s]                                                                                                                                                                                                                                              \n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "for batch in tqdm.tqdm(ds.iter(batch_size), total=len(ds) // batch_size):\n",
    "    embeddings = model.generate_embeddings(batch[\"positive\"])\n",
    "    df = pd.DataFrame.from_dict({\"query\": batch[\"positive\"], \"text\": batch[\"anchor\"], \"vector\": embeddings})\n",
    "    table.add(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "fb7b474e-8657-4580-8702-0a8af0dbcba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0\n",
      "python\n",
      "user = client.users(\"my_username\")\n",
      "\n",
      "The current user of the rg.Argilla client can be accessed using the me attribute:\n",
      "\n",
      "python\n",
      "client.me\n",
      "\n",
      "Class Reference\n",
      "\n",
      "rg.User\n",
      "\n",
      "::: argilla_sdk.users.User\n",
      "    options:\n",
      "        heading_level: 3\n",
      "----- 2\n",
      "Retrieve a user\n",
      "\n",
      "You can retrieve an existing user from Argilla by accessing the users attribute on the Argilla class and passing the username as an argument.\n",
      "\n",
      "```python\n",
      "import argilla_sdk as rg\n",
      "\n",
      "client = rg.Argilla(api_url=\"\", api_key=\"\")\n",
      "\n",
      "retrieved_user = client.users(\"my_username\")\n",
      "```\n",
      "----- 5\n",
      "!!! info \"Main Class\"\n",
      "\n",
      "Get current user\n",
      "\n",
      "To ensure you're using the correct credentials for managing users, you can get the current user in Argilla using the me attribute of the Argilla class.\n",
      "\n",
      "```python\n",
      "import argilla_sdk as rg\n",
      "\n",
      "client = rg.Argilla(api_url=\"\", api_key=\"\")\n",
      "\n",
      "current_user = client.me\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I create a feedback dataset in argilla?\"\n",
    "query = \"How can I connect to an argilla server?\"\n",
    "query = \"How can I create a dataset?\"\n",
    "query = \"How can I get the current user?\"\n",
    "\n",
    "response = table.search(query).limit(12).select([\"text\"]).to_list()#.to_pydantic(Docs)\n",
    "hard_limit = 3\n",
    "unique_responses = set()\n",
    "ctr = 0\n",
    "for i, d in enumerate(response):\n",
    "    chunk = d[\"text\"]\n",
    "    if chunk not in unique_responses:\n",
    "        unique_responses.add(chunk)\n",
    "        print(\"-----\", i)\n",
    "        print(chunk)\n",
    "        ctr += 1\n",
    "        if ctr == hard_limit:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55021205-ea86-4bfa-8c7a-a79f788fd3c5",
   "metadata": {},
   "source": [
    "## Database\n",
    "\n",
    "The database is a folder small enough that we can zip it and move it around, then load it and start making queries.\n",
    "\n",
    "[ref](https://github.com/plaguss/talking-python/blob/main/src/talking_python/release.py) to compress/uncompress the db and pass it around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "f6a4b934-75e3-4bcc-b7a6-126c4fdfeb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from urllib.error import HTTPError, URLError\n",
    "from urllib.request import urlopen\n",
    "import tqdm\n",
    "import inspect\n",
    "\n",
    "import requests\n",
    "\n",
    "#RELEASES_URL = r\"https://github.com/plaguss/talking-python/releases\"\n",
    "#RELEASES_ENDPOINT = r\"https://api.github.com/repos/plaguss/talking-python/releases\"\n",
    "\n",
    "\n",
    "DATE_FORMAT = \"%Y%m%d-%H%M\"\n",
    "\n",
    "def make_tarfile(source: Path) -> Path:\n",
    "    \"\"\"Creates a tar file from a directory and compresses it\n",
    "    using gzip.\n",
    "\n",
    "    Args:\n",
    "        source (Path): Path to a directory.\n",
    "\n",
    "    Returns:\n",
    "        path (Path): Path of the new generated file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the directory doesn't exists.\n",
    "    \"\"\"\n",
    "    print(f\"Creating tar file from path: {source}...\")\n",
    "    source = Path(source)\n",
    "    if not source.is_dir():\n",
    "        raise FileNotFoundError(source)\n",
    "    with tarfile.open(str(source) + \".tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(str(source), arcname=source.name)\n",
    "    print(f\"File generated at: {str(source) + '.tar.gz'}\")\n",
    "    return Path(str(source) + \".tar.gz\")\n",
    "\n",
    "def untar_file(source: Path) -> Path:\n",
    "    \"\"\"Untar and decompress files which have passed by `make_tarfile`.\n",
    "\n",
    "    Args:\n",
    "        source (Path): Path pointing to a .tag.gz file.\n",
    "\n",
    "    Returns:\n",
    "        filename (Path): The filename of the file decompressed.\n",
    "    \"\"\"\n",
    "    # It assumes the file ends with .tar.gz\n",
    "    new_filename = source.parent / source.stem.replace(\".tar\", \"\")\n",
    "    with tarfile.open(source, \"r:gz\") as f:\n",
    "        f.extractall(source.parent)\n",
    "    print(f\"File decompressed: {new_filename}\")\n",
    "    return new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "03c7667e-1dc5-493c-8131-129b9d19d003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tar file from path: /Users/agus/github_repos/argilla-io/distilabel-workbench/projects/argilla-sdk-bot/lancedb...\n",
      "File generated at: /Users/agus/github_repos/argilla-io/distilabel-workbench/projects/argilla-sdk-bot/lancedb.tar.gz\n"
     ]
    }
   ],
   "source": [
    "lancedb_path = Path.cwd() / \"lancedb\"\n",
    "lancedb_tar = make_tarfile(lancedb_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "1eed11bc-1f52-4d24-97a7-90bee6cbd45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.11/site-packages (0.23.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "34ef1d30-c2a7-490c-9765-8c2db7726968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub.file_download import hf_hub_download\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "03c65ae8-9644-48ce-9b8d-a9ecbf4a442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lancedb_file = \"lancedb.tar.gz\"\n",
    "token = os.getenv(\"HF_API_TOKEN\")\n",
    "local_dir = Path.home() / \".cache/argilla_sdk_docs_db\"\n",
    "repo_id = \"plaguss/argilla_sdk_docs_queries\"\n",
    "lancedb_download = Path(\n",
    "    hf_hub_download(\n",
    "        repo_id,\n",
    "        lancedb_file,\n",
    "        repo_type=\"dataset\",\n",
    "        token=token,\n",
    "        local_dir=local_dir\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "d974157e-1a6c-4d40-a7c3-abfe86eeae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File decompressed: /Users/agus/.cache/argilla_sdk_docs_db/lancedb\n"
     ]
    }
   ],
   "source": [
    "lancedb_db_path = untar_file(lancedb_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8651f7-fc84-4a4b-a1fd-d91b7545030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "\n",
    "db = lancedb.connect(str(lancedb_db_path))\n",
    "table_name = \"docs\"\n",
    "table = db.open_table(table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "61c82ebd-b589-416c-84dd-3282d95fd421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----QUERY\n",
      "Is it possible to remove a user from Argilla by utilizing the delete function on the User class?\n",
      "======\n",
      "DOC\n",
      "\n",
      "======\n",
      "Delete a user\n",
      "\n",
      "You can delete an existing user from Argilla by calling the delete method on the User class.\n",
      "\n",
      "```python\n",
      "import argilla_sdk as rg\n",
      "\n",
      "client = rg.Argilla(api_url=\"\", api_key=\"\")\n",
      "\n",
      "user_to_delete = client.users('my_username')\n",
      "\n",
      "deleted_user = user_to_delete.delete()\n",
      "```\n",
      "-----QUERY\n",
      "How do I go about deleting a user from Argilla using the delete method provided by the User class?\n",
      "======\n",
      "DOC\n",
      "\n",
      "======\n",
      "Delete a user\n",
      "\n",
      "You can delete an existing user from Argilla by calling the delete method on the User class.\n",
      "\n",
      "```python\n",
      "import argilla_sdk as rg\n",
      "\n",
      "client = rg.Argilla(api_url=\"\", api_key=\"\")\n",
      "\n",
      "user_to_delete = client.users('my_username')\n",
      "\n",
      "deleted_user = user_to_delete.delete()\n",
      "```\n",
      "-----QUERY\n",
      "Can I delete a user from Argilla using the delete method on the User class?\n",
      "======\n",
      "DOC\n",
      "\n",
      "======\n",
      "Delete a user\n",
      "\n",
      "You can delete an existing user from Argilla by calling the delete method on the User class.\n",
      "\n",
      "```python\n",
      "import argilla_sdk as rg\n",
      "\n",
      "client = rg.Argilla(api_url=\"\", api_key=\"\")\n",
      "\n",
      "user_to_delete = client.users('my_username')\n",
      "\n",
      "deleted_user = user_to_delete.delete()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"How can I create a feedback dataset in argilla?\"\n",
    "query = \"how can I delete users?\"\n",
    "\n",
    "retrieved = (\n",
    "    table\n",
    "    .search(query)\n",
    "    .metric(\"cosine\")\n",
    "    .limit(3)\n",
    "    .to_pydantic(Docs)\n",
    ")\n",
    "for d in retrieved:\n",
    "    print(\"-----QUERY\")\n",
    "    print(d.query)\n",
    "    print(\"======\")\n",
    "    print(\"DOC\\n\")\n",
    "    print(\"======\")\n",
    "    print(d.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "1a7ac403-d75f-4ca6-b44f-5d05cf4dec27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Delete a user\n",
      "\n",
      "You can delete an existing user from Argilla by calling the delete method on the User class.\n",
      "\n",
      "```python\n",
      "import argilla_sdk as rg\n",
      "\n",
      "client = rg.Argilla(api_url=\"\", api_key=\"\")\n",
      "\n",
      "user_to_delete = client.users('my_username')\n",
      "\n",
      "deleted_user = user_to_delete.delete()\n",
      "```\n",
      "======\n",
      "Delete a user\n",
      "\n",
      "You can delete an existing user from Argilla by calling the delete method on the User class.\n",
      "\n",
      "```python\n",
      "import argilla_sdk as rg\n",
      "\n",
      "client = rg.Argilla(api_url=\"\", api_key=\"\")\n",
      "\n",
      "user_to_delete = client.users('my_username')\n",
      "\n",
      "deleted_user = user_to_delete.delete()\n",
      "```\n",
      "======\n",
      "Delete a user\n",
      "\n",
      "You can delete an existing user from Argilla by calling the delete method on the User class.\n",
      "\n",
      "```python\n",
      "import argilla_sdk as rg\n",
      "\n",
      "client = rg.Argilla(api_url=\"\", api_key=\"\")\n",
      "\n",
      "user_to_delete = client.users('my_username')\n",
      "\n",
      "deleted_user = user_to_delete.delete()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"how can I delete users?\"\n",
    "\n",
    "retrieved = (\n",
    "    table\n",
    "    .search(query)\n",
    "    .limit(3)\n",
    "    .to_pydantic(Docs)\n",
    ")\n",
    "for d in retrieved:\n",
    "    print(\"======\")\n",
    "    print(d.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "d39fefbc-1afe-4fda-8ddd-bc257abd315a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Docs(query='How do I create a dataset in Argilla?', text='Create a dataset\\n\\nTo create a dataset, you can define it in the Dataset class and then call the create method that will send the dataset to the server so that it can be visualized in the UI. If the dataset does not appear in the UI, you may need to click the refresh button to update the view. For further configuration of the dataset, you can refer to the settings section.\\n\\nThe created dataset will be empty, to add the records refer to this how-to guide.\\n\\n```python\\nimport argilla_sdk as rg', vector=FixedSizeList(dim=768)),\n",
       " Docs(query='I need help creating a dataset in Argilla', text='For a detail guide of the dataset creation and publication process, see the Dataset how to guide.\\n\\nRetrieving an existing Dataset\\n\\nTo retrieve an existing dataset, use client.datasets(\"my_dataset\") instead.\\n\\npython\\ndataset = client.datasets(\"my_dataset\")\\n\\nClass Reference\\n\\nrg.Dataset\\n\\n::: argilla_sdk.datasets.Dataset\\n    options:\\n        heading_level: 3', vector=FixedSizeList(dim=768)),\n",
       " Docs(query='Is it possible for Argilla users to craft their own questions to obtain precise feedback from annotators on their datasets?', text='hide: footer\\n\\nQuestions\\n\\nQuestions in Argilla are the questions that will be answered as feedback. They are used to define the questions that will be answered by users or models.', vector=FixedSizeList(dim=768))]"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "c1a6fe55-7baa-498a-b854-ffea83f255d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"HF_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "a6521a96-da7f-412d-8ff3-b4620f765fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import (\n",
    "    AsyncInferenceClient,\n",
    "    InferenceClient,\n",
    "    get_inference_endpoint,\n",
    ")\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = tokenizer_id = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "client = InferenceClient()\n",
    "status = client.get_model_status(model_id)\n",
    "base_url = client._resolve_url(\n",
    "    model=model_id, task=\"text-generation\"\n",
    ")\n",
    "client = InferenceClient(\n",
    "    model=base_url,\n",
    "    token=os.getenv(\"HF_API_TOKEN\")\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
    "#aclient = AsyncInferenceClient(\n",
    "#    model=base_url,\n",
    "#    token=api_key,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "3daba544-b002-4435-9282-7f996bc6df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_kwargs = {\n",
    "    \"stream\": True,\n",
    "    \"max_new_tokens\": 12,\n",
    "    \"do_sample\": False,\n",
    "    \"typical_p\": None,\n",
    "    \"repetition_penalty\": None,\n",
    "    \"temperature\": 0.3,\n",
    "    \"top_p\": None,\n",
    "    \"top_k\": None,\n",
    "    \"stop_sequences\": None,\n",
    "    \"seed\": None,\n",
    "}\n",
    "\n",
    "query = \"How do you make cheese?\"\n",
    "input = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query,\n",
    "        },\n",
    "    ]\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(  # type: ignore\n",
    "    conversation=input,  # type: ignore\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "70ee1de0-cb89-42a0-a951-05d64facf4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do you make cheese?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "89991f54-c528-43b4-8201-2154648a8bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making\n",
      "Making cheese\n",
      "Making cheese is\n",
      "Making cheese is a\n",
      "Making cheese is a fascinating\n",
      "Making cheese is a fascinating process\n",
      "Making cheese is a fascinating process that\n",
      "Making cheese is a fascinating process that involves\n",
      "Making cheese is a fascinating process that involves transforming\n",
      "Making cheese is a fascinating process that involves transforming milk\n",
      "Making cheese is a fascinating process that involves transforming milk into\n",
      "Making cheese is a fascinating process that involves transforming milk into a\n"
     ]
    }
   ],
   "source": [
    "partial_message = \"\"\n",
    "for token in client.text_generation(prompt=prompt, **client_kwargs):\n",
    "    partial_message += token\n",
    "    print(partial_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322ba14-5b82-4e41-8da0-f7792dd3c16c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
