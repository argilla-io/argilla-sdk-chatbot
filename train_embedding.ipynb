{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b911ac-bfae-4bc4-a018-b663f8946960",
   "metadata": {},
   "source": [
    "## Fine tuning our embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f4110-ccd5-4c83-8d3f-7c9c34970a9f",
   "metadata": {},
   "source": [
    "### Thanks to [philschmid's](https://www.philschmid.de/fine-tune-embedding-model-for-rag) blog.\n",
    "\n",
    "You can read the blog entry, this notebook is a copy with some modifications to our specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54405ee-ca7f-4194-bd7e-258b813766f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the requirements from the file\n",
    "!pip install -r requirements/requirements_training.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e82cb2-7e63-47f1-8feb-7e28984aca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb4826-c716-4d79-9cc9-8f9676cf96c9",
   "metadata": {},
   "source": [
    "### Load our dataset and prepare it for training\n",
    "\n",
    "Let's download the dataset with the chunks of the documentation and the synthetic queries.\n",
    "\n",
    "The dataset was made of triplets, so we will select those, split the content into train/test, and save the content to a json file locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78ddcb26-9c66-4ffb-b9b7-1a2b5ebe9bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.10k/4.10k [00:00<00:00, 3.95MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 137k/137k [00:00<00:00, 231kB/s]\n",
      "Generating train split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 980/980 [00:00<00:00, 50210.32 examples/s]\n",
      "Creating json from Arrow format: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 22.54ba/s]\n",
      "Creating json from Arrow format: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 260.27ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62366"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset from the hub\n",
    "dataset = (\n",
    "    load_dataset(\"plaguss/argilla_sdk_docs_queries\", split=\"train\")\n",
    "    .select_columns([\"anchor\", \"positive\", \"negative\"])  # Select the relevant columns\n",
    "    .add_column(\"id\", range(len(dataset)))               # Add an id column to the dataset\n",
    "    .train_test_split(test_size=0.1)                     # split dataset into a 10% test set\n",
    ")\n",
    " \n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e8ac31-a117-48f6-8644-4c6e65c3865f",
   "metadata": {},
   "source": [
    "### Load back the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10090aeb-d290-4b88-8496-9eeb713352c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 98 examples [00:00, 10590.04 examples/s]\n",
      "Generating train split: 882 examples [00:00, 134025.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "test_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "corpus_dataset = concatenate_datasets([train_dataset, test_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027dff97-2273-4fde-a622-3a6c553f8d7d",
   "metadata": {},
   "source": [
    "Define the name of the model we want to fine tune, and some variables to determine the type of fine tuning, following the blog,\n",
    "we are doing a [Matryoshka embedding model](https://huggingface.co/blog/matryoshka)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45c45438-5504-4b34-a870-d550f0fd844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"BAAI/bge-base-en-v1.5\"  # Hugging Face model ID\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64]  # Important: large to small\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca54c3-593f-46d8-b188-0e3d9790c2b8",
   "metadata": {},
   "source": [
    "## Prepare the evaluator\n",
    "\n",
    "Let's define the evaluator for the model to see the initial base model we want to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a80586fb-df4d-4c7e-a712-dee6581ddb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(\n",
    "    zip(corpus_dataset[\"id\"], corpus_dataset[\"positive\"])\n",
    ")  # Our corpus (cid => document)\n",
    "queries = dict(\n",
    "    zip(test_dataset[\"id\"], test_dataset[\"anchor\"])\n",
    ")  # Our queries (qid => question)\n",
    " \n",
    "# Create a mapping of relevant document (1 in our case) for each query\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for q_id in queries:\n",
    "    relevant_docs[q_id] = [q_id]\n",
    " \n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    " \n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0941004c-4021-4dea-996a-e7c7cca8481e",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a687ed1-5bd0-4ece-9bd0-3caaedf19824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_768_cosine_ndcg@10: 0.30804996520618816\n",
      "dim_512_cosine_ndcg@10: 0.29105806175342075\n",
      "dim_256_cosine_ndcg@10: 0.27984055715264694\n",
      "dim_128_cosine_ndcg@10: 0.24651526191432124\n",
      "dim_64_cosine_ndcg@10: 0.2384123532612535\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = evaluator(model)\n",
    " \n",
    "# # COMMENT IN for full results\n",
    "# print(results)\n",
    " \n",
    "# Print the main score\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adfc91b-a3a6-4ece-825b-94139721901e",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a2d939a-e38d-4060-8a18-ff125eb21065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerModelCardData, SentenceTransformer\n",
    " \n",
    "# Hugging Face model ID: https://huggingface.co/BAAI/bge-base-en-v1.5\n",
    "model_id = \"BAAI/bge-base-en-v1.5\"\n",
    " \n",
    "# load model with SDPA for using Flash Attention 2\n",
    "model = SentenceTransformer(\n",
    "    model_id,\n",
    "    #model_kwargs={\"attn_implementation\": \"sdpa\"},  # sdpa will be used by default if available\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"BGE base ArgillaSDK Matryoshka\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8552d70-600d-4d0c-83eb-8fc67eef64bc",
   "metadata": {},
   "source": [
    "#### Define the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9777219e-2860-4a26-ac01-ae262559b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MatryoshkaLoss, TripletLoss\n",
    " \n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64]  # Important: large to small\n",
    "inner_train_loss = TripletLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87769601-e3cf-4d2b-b6f4-472a0988de83",
   "metadata": {},
   "source": [
    "## Define the training strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da07d4-811a-4c26-8b40-e970d132f3d7",
   "metadata": {},
   "source": [
    "The training strategy was slightly modified from the original reference to run on a `Apple M2 Pro` instead of the original machine,\n",
    "hence the change of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91a2fc6f-7fcc-44c8-be23-aa5ae8f07735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "  \n",
    "# define training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"bge-base-argilla-sdk-matryoshka\", # output directory and hugging face model ID\n",
    "    num_train_epochs=3,                         # number of epochs\n",
    "    per_device_train_batch_size=8,             # train batch size\n",
    "    gradient_accumulation_steps=4,             # for a global batch size of 512\n",
    "    per_device_eval_batch_size=4,              # evaluation batch size\n",
    "    warmup_ratio=0.1,                           # warmup ratio\n",
    "    learning_rate=2e-5,                         # learning rate, 2e-5 is a good value\n",
    "    lr_scheduler_type=\"cosine\",                 # use constant learning rate scheduler\n",
    "# NOTE: In colab we can work with the optimizer at least, but neither tf32 nor bf16\n",
    "#    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
    "#    tf32=True,                                  # use tf32 precision\n",
    "#    bf16=True,                                  # use bf16 precision\n",
    "    #batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"epoch\",                      # evaluate after each epoch\n",
    "    save_strategy=\"epoch\",                      # save after each epoch\n",
    "    logging_steps=5,                            # log every 10 steps\n",
    "    save_total_limit=1,                         # save only the last 3 models\n",
    "    load_best_model_at_end=True,                # load the best model when training ends\n",
    "    metric_for_best_model=\"eval_dim_512_cosine_ndcg@10\",  # Optimizing for the best ndcg@10 score for the 512 dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c7770-82a5-4dec-a5b2-ef88dfeaf4f6",
   "metadata": {},
   "source": [
    "### Remove None from datasets\n",
    "\n",
    "The dataset can have some `None` values, remove them before starting the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1715084b-495e-475b-abe0-32c61c1a8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset_cleaned = train_dataset.select_columns(\n",
    "    [\"anchor\", \"positive\", \"negative\"]\n",
    ").to_pandas().dropna()\n",
    "test_dataset_cleaned = test_dataset.select_columns(\n",
    "    [\"anchor\", \"positive\", \"negative\"]\n",
    ").to_pandas().dropna()\n",
    "\n",
    "train_dataset_cleaned = Dataset.from_pandas(train_dataset_cleaned, preserve_index=False)\n",
    "test_dataset_cleaned = Dataset.from_pandas(test_dataset_cleaned, preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8a637-b2e2-492d-aab3-213c43c58806",
   "metadata": {},
   "source": [
    "### Prepare the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8e04175-40a6-4b05-b36a-cd78fc209ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    " \n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model, # bg-base-en-v1\n",
    "    args=args,  # training arguments\n",
    "    train_dataset=train_dataset.select_columns(\n",
    "        [\"anchor\", \"positive\", \"negative\"]\n",
    "    ),  # training dataset\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f29842-c904-4879-9f12-998549330d10",
   "metadata": {},
   "source": [
    "### Train the model, and save it publicly on your account in the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2742e6-688d-4132-bd7a-77d59b32855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    " \n",
    "# save the best model\n",
    "trainer.save_model()\n",
    " \n",
    "# push model to hub\n",
    "trainer.model.push_to_hub(\"bge-base-argilla-sdk-matryoshka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccecb2e6-7dd7-4292-8137-fc6cdfcf0563",
   "metadata": {},
   "source": [
    "#### Evaluate the final model on the same eval data to see the potential improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6851b74d-3d67-479a-80b5-f5c0b3092278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agus/github_repos/argilla-io/distilabel-workbench/projects/argilla-sdk-bot/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_768_cosine_ndcg@10: 0.3086125494748455\n",
      "dim_512_cosine_ndcg@10: 0.29420081448590024\n",
      "dim_256_cosine_ndcg@10: 0.2931450934182018\n",
      "dim_128_cosine_ndcg@10: 0.2629197762336244\n",
      "dim_64_cosine_ndcg@10: 0.2610977190273289\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "fine_tuned_model = SentenceTransformer(\n",
    "    \"plaguss/bge-base-argilla-sdk-matryoshka\", device=device\n",
    ")\n",
    "# Evaluate the model\n",
    "results = evaluator(fine_tuned_model)\n",
    " \n",
    "# # COMMENT IN for full results\n",
    "# print(results)\n",
    " \n",
    "# Print the main score\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
